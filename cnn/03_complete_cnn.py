import torch 
import torch.nn as nn 
import torch.nn.functional as F 
from torch.utils.data import DataLoader
from torchvision import datasets, transforms 


# basic cnn 

class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        # 1,32 are shapes, 3 is kernel size  
        self.conv1 = nn.Conv2d(1,32,3) # why? 
        # because input image is 28x28, after conv1 it becomes 26x26
        # so after pooling it becomes 13x13
        self.conv2 = nn.Conv2d(32, 64, 3)
        # after conv2 it becomes 11x11
        self.pool = nn.MaxPool2d(2,2)
        # after pooling it becomes 5x5
        self.fc1 = nn.Linear(64 * 5 * 5, 128) # why this size? 
        # because after conv and pool, the feature map size is 64 channels of 5x5
        # after fc1 it becomes 120
        # channels here mean feature maps which are generated by filters doing convolution
        self.fc2 = nn.Linear(128, 10)
        
    def forward(self, x):
        
        # x = self.pool(F.relu(self.conv1(x))) # why relu? 
        x = self.conv1(x)
        x = F.relu(x)
        x = self.pool(x)
        # beacuse relu introduces non-linearity
        # x = self.pool(F.relu(self.conv2(x)))
        x = self.conv2(x)
        x = F.relu(x)
        x = self.pool(x)
        x = x.view(-1, 64 * 5 * 5) # flatten the tensor 
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x

model = SimpleCNN()
print(model)
print(f"\nParameters: {sum(p.numel() for p in model.parameters()):,}")
     
# Test forward pass
test_in = torch.randn(2, 1, 28, 28)
test_out = model(test_in)
print(f"\nTest: {test_in.shape} â†’ {test_out.shape}")




class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1= nn.Conv2d(1, 32,3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3= nn.Conv2d(64, 128,3, padding=1)
        self.bn3 = nn.BatchNorm3d(128)
        self.pool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(128 * 3 * 3, 256)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(256, 10)
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.pool(x)
        x= self.pool(F.relu(self.bn2(self.conv2)))
        x = self.pool(F.relu(self.bn3(self.conv3)))
        x = x.view(-1, 128 * 3*3)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

cnn = CNN()

print(cnn)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CNN().to(device)
optimizer=torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.CrossEntropyLoss()

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081))
])

train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)

def train_epoch(model, loader, optimizer, loss_fn, device):
    model.train()
    total_loss=0
    correct=0
    total=0

    for batch_idx, (data,targets) in enumerate(loader):
        data, targets = data.to(device), targets.to(device)

        optimizer.zero_grad()

        outputs = model(data)

        loss = loss_fn(outputs, targets)

        loss.backward()

        optimizer.step()

        total_loss += loss.item()

        pred = outputs.argmax(dim=1)
        correct += (pred == targets).sum().item()
        total += targets.size(0)

        if batch_size % 100 ==0 :
            print(f"[{batch_idx}/{len(loader)}] Loss: {loss.item():.4f} Acc: {100*correct/total:.2f}%")

    return total_loss / len(loader), correct/total

train_loss, train_acc = train_epoch(model, train_loader, optimizer,
                                    loss_fn, device)
print(f"\nEpoch complete: Loss={train_loss:.4f}, Acc={train_acc*100:.2f}%")







