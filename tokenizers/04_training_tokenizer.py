# training custom tokenizer from scratch
# building vocabulary specific to your domain

# topics to cover:
# - Tokenizer() and BpeTrainer initialization
# - training on text files or iterators
# - setting vocabulary size
# - special tokens configuration
# - save_model() and loading back
# - when to train custom vs use pretrained
# - domain specific vocabularies (code, medical, etc)
# - comparing custom tokenizer to general purpose ones

# OBJECTIVE: train tokenizer on domain specific corpus
# understand when custom tokenization helps vs pretrained
