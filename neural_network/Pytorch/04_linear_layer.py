# implementing linear layer from scratch
# the most fundamental building block of neural networks

# topics to cover:
# - linear transformation: y = Wx + b
# - weight initialization (why random, not zeros)
# - forward pass computation
# - understanding parameter shapes
# - connection to matrix multiplication
# - bias term (optional but important)
